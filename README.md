# ğŸ“ˆ PrevisÃ£o de SÃ©ries Temporais Financeiras (PETR4.SA)

## ğŸ¯ Objetivo

Este projeto atende ao desafio de desenvolver um modelo preditivo baseado em **LSTM (Long Short-Term Memory)** para prever o **preÃ§o de fechamento (D+1)** de uma aÃ§Ã£o da bolsa â€” aqui, **PETR4.SA**.

A soluÃ§Ã£o implementa **toda a pipeline completa**, abrangendo:

- coleta e preparaÃ§Ã£o de dados,
- modelagem e treinamento,
- rastreamento de experimentos,
- deploy do modelo em uma API REST para inferÃªncia,
- monitoramento contÃ­nuo do serviÃ§o.

O projeto demonstra:

- **Modelo LSTM (PyTorch + PyTorch Lightning)** integrado a um pipeline de treinamento estruturado.
- **Rastreabilidade com MLflow:** parÃ¢metros, mÃ©tricas, artefatos.
- **Deploy escalÃ¡vel** via FastAPI com monitoramento por Prometheus.

---

## ğŸŒŸ Arquitetura da SoluÃ§Ã£o (MLOps)

A arquitetura segue o princÃ­pio de **serviÃ§os desacoplados**, separando **treinamento** de **inferÃªncia** para garantir escalabilidade e governanÃ§a.

### Componentes

- **Treinamento â€” `train.py` + PyTorch Lightning**  
  ResponsÃ¡vel por coleta de dados, criaÃ§Ã£o do dataset, construÃ§Ã£o e treinamento do modelo LSTM.

- **InferÃªncia â€” FastAPI (`app/api/main.py`)**  
  API REST que serve o modelo em produÃ§Ã£o com baixa latÃªncia.

- **Rastreabilidade â€” MLflow (SQLite)**  
  Registra cada execuÃ§Ã£o com mÃ©tricas, hiperparÃ¢metros e artefatos.

- **Monitoramento â€” Prometheus**  
  Coleta mÃ©tricas como latÃªncia das requisiÃ§Ãµes e MAE do modelo.

---

## ğŸ› ï¸ Detalhes de ImplementaÃ§Ã£o

### Linguagem e Frameworks

- **Python 3.12.6**
- **PyTorch** â€“ implementaÃ§Ã£o da rede LSTM  
- **PyTorch Lightning** â€“ estrutura e treinamento modularizado  
- **FastAPI** â€“ API REST de inferÃªncia  
- **MLflow** â€“ tracking de experimentos  

### Principais dependÃªncias

- `pandas`, `numpy`, `datetime` â€“ manipulaÃ§Ã£o de dados  
- `yfinance` â€“ coleta de dados financeiros  
- `scikit-learn` â€“ `MinMaxScaler`  
- `torchmetrics` â€“ mÃ©tricas (MAE)  
- `prometheus_client` â€“ monitoramento de serviÃ§o  
- `joblib` â€“ carregamento/salvamento de scaler 
* `uvicorn` (Servidor ASGI). 

### Arquitetura do Modelo

- **LSTM empilhada (duas camadas)** para previsÃ£o de sÃ©ries temporais  
- **`LSTMFactory`** â€“ mÃ³dulo com a arquitetura da rede  
- **`LSTMLightModule`** â€“ mÃ³dulo Lightning que gerencia ciclo de treino, validaÃ§Ã£o e teste  

---

## âœ¨ Principais Conceitos TÃ©cnicos

### ğŸ§  Modelo LSTM

- Arquitetura de duas camadas LSTM com integraÃ§Ã£o ao PyTorch Lightning.
- Reprodutibilidade assegurada com `pl.seed_everything(42)` e `shuffle=False` no DataLoader.

### ğŸ’¾ Deploy (FastAPI)

- Treinamento via CLI e inferÃªncia online desacoplada.
- Carregamento Ãºnico do modelo e scaler no `lifespan`, garantindo baixa latÃªncia.
- `state.py` mantÃ©m instÃ¢ncias globais de `MODEL` e `SCALER` acessÃ­veis a toda a API.

---

## ğŸ“ˆ Monitoramento e EvoluÃ§Ã£o (Sustentabilidade)

### ğŸ” Retreinamento (MLOps)

- **MAE em escala original** Ã© a mÃ©trica crÃ­tica para avaliar a saÃºde do modelo.
- A arquitetura jÃ¡ possui:
  - **mediÃ§Ã£o** (Prometheus)  
  - **aÃ§Ã£o** (`train.py`)  
- Futuro: automatizar o retreinamento acionado por alertas de MAE.

### â±ï¸ Monitoramento de SLA

- **GET `/metrics`** expÃµe mÃ©tricas de latÃªncia e contagem de requisiÃ§Ãµes.
- O SLA pode ser acompanhado via Prometheus/Grafana.

---

## ğŸ—‚ï¸ Estrutura do Projeto

```text
prj-lstm-petr4/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/          
â”‚   â”‚   â”œâ”€â”€ router/
â”‚   â”‚   â”œâ”€â”€ main.py      # FastAPI com Lifespan e Middleware
â”‚   â”‚   â””â”€â”€ state.py     # Estado global (MODEL/SCALER)
â”‚   â”œâ”€â”€ artifacts/        # Checkpoints, scaler.pkl, mlflow.db
â”‚   â”œâ”€â”€ config/           # Settings
â”‚   â”œâ”€â”€ data/             # Pipeline de dados (coleta, Dataset)
â”‚   â”œâ”€â”€ model/            # LSTMFactory e LSTMLightModule
â”‚   â”œâ”€â”€ schemas/          # Entradas/SaÃ­das da API (Pydantic)
â”‚   â””â”€â”€ utils/            # FunÃ§Ãµes auxiliares
â”œâ”€â”€ mlruns/               # Artefatos MLflow
â”œâ”€â”€ requirements.txt
â””â”€â”€ train.py              # Script de Treinamento
```
## ğŸ’» ExecuÃ§Ã£o Local (Windows + Docker + API + Monitoramento)
Esta aplicaÃ§Ã£o faz uso de Prometheus e Grafana para monitoramento em tempo real.
Para uma reproduÃ§Ã£o no Windows, Ã© necessÃ¡rio utilizar o Docker Desktop para subir os contÃªineres automaticamente.
VocÃª pode rodar tudo manualmente ou simplesmente utilizar o script **start_ambiente.py**, que:
- Inicia o Docker Desktop
  - Importante jÃ¡ constar instalado, Baixe em: https://www.docker.com/products/docker-desktop/ 
- Sobe (ou cria, se nÃ£o existir) os contÃªineres **prometheus_petr4** e **grafana_petr4**
- Abre automaticamente as URLs no navegador
  - Host Grafana: http://localhost:3000
  - Host Prometheus: http://localhost:9090/targets
- Inicia o servidor FastAPI (Uvicorn)
  - Host API: http://127.0.0.1:8000/docs

Obs.: Para executar o script **start_ambiente.py** Ã© importante seguir primeiro os passos abaixo.

### ğŸš€ Passos para ExecuÃ§Ã£o Local

```bash
# 1. Clone o repositÃ³rio
git clone https://github.com/ManoelSa/prj-lstm-petr4.git
cd prj-lstm-petr4

# 2. (Opcional) Crie e ative um ambiente virtual
python -m venv venv
venv\Scripts\activate #Linux: source venv/bin/activate

# 3. Instale as dependÃªncias
pip install -r requirements.txt

# 4. Execute o pipeline de treinamento
python train.py
# SaÃ­da esperada: O modelo serÃ¡ treinado por 50 Ã©pocas e os artefatos serÃ£o salvos em 'artifacts/'
```
## ğŸ” AnÃ¡lise de Experimentos com MLflow

ApÃ³s iniciar os steps atenteriores, Ã© hora de explorar, comeÃ§ando com interface do MLflow:
-  Execute: `mlflow ui --backend-store-uri sqlite:///app/artifacts/mlflow.db`
- Host: `http://127.0.0.1:5000/`

Utilize os seguintes pontos para analisar a performance e a rastreabilidade do modelo:

### 1. Rastreamento e Reprodutibilidade (ParÃ¢metros)

Ao clicar no ID de uma **Run (ExecuÃ§Ã£o)**, o primeiro foco Ã© na seÃ§Ã£o **ParÃ¢metros**.

* **VerificaÃ§Ã£o de HiperparÃ¢metros:** Confirme que os parÃ¢metros do modelo (`hidden_size`, `dropout_rate`, `learning_rate`) e do treino (`epochs`, `batch_size`) foram logados automaticamente pelo PyTorch Lightning.
* **VerificaÃ§Ã£o de ParÃ¢metros de Dados:** Procure os logs manuais (`data_ticker`, `data_time_step`, `data_start_date`). **Estes comprovam a rastreabilidade:** possibilitando saber exatamente com quais configuraÃ§Ãµes e dados o modelo foi treinado.

### 2. AnÃ¡lise de Desempenho (MÃ©tricas)

Utilize a seÃ§Ã£o **MÃ©tricas** para avaliar a qualidade do modelo ao longo do tempo.

* **Curva de `val_loss` (Perda de ValidaÃ§Ã£o):** Este Ã© o grÃ¡fico mais importante. A curva deve cair de forma consistente e depois se estabilizar. Se a curva comeÃ§ar a subir, indica **overfitting** (o modelo estÃ¡ memorizando o treino e perdendo a capacidade de generalizaÃ§Ã£o).
* **MÃ©trica de ProduÃ§Ã£o (`test_mae`):** Verifique o valor final do `test_mae` (Mean Absolute Error). Este valor, que Ã© uma **mÃ©trica escalonada**, deve ser baixo. Ele se correlaciona diretamente com o **MAE em R$** calculado na etapa final do `train.py`.

A interface do **MLflow** atua como o Registro de Experimentos (Model Registry), fornecendo um histÃ³rico completo para auditoria e garantindo que o modelo seja rastreÃ¡vel e auditÃ¡vel.


## ğŸ“Š Monitoramento em Grafana (AnÃ¡lise de ProduÃ§Ã£o)

Para analisar a saÃºde do serviÃ§o (SLA) e a efetividade do modelo, utilizamos o Prometheus e o Grafana, habilitados nos passos anteriores.

Apesar da automaÃ§Ã£o, ainda Ã© necessÃ¡rio realizar duas configuraÃ§Ãµes manuais no Grafana:

1.  **ConexÃ£o do Data Source (Prometheus):**
    * Acesse o Grafana (`http://localhost:3000`).
    * VÃ¡ para **Data Sources** e adicione o Prometheus.
    * No campo **URL**, utilize o endereÃ§o do serviÃ§o: `http://host.docker.internal:9090` (Este Ã© o endereÃ§o que permite ao Grafana acessar o Prometheus que estÃ¡ rodando no contÃªiner).
    * Clique em "Save & Test".

2.  **ImportaÃ§Ã£o do Dashboard:**
    * VÃ¡ para `Dashboards` -> `New` -> `Import`.
    * Selecione o JSON do seu dashboard (localizado na pasta `metrics/`).
    * Na importaÃ§Ã£o, estabeleÃ§a um nome e uma pasta para seu dashboard, e fim, pronto para uso.
  
---

> â„¹ï¸ **Aviso:** Esta API e o modelo LSTM tÃªm fins **educacionais e de pesquisa**. O conteÃºdo gerado nÃ£o deve ser utilizado como base para decisÃµes financeiras ou de investimento.