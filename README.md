# ğŸ“ˆ PrevisÃ£o de SÃ©ries Temporais Financeiras (PETR4.SA)

## ğŸ¯ Objetivo

Este projeto atende ao desafio de desenvolver um modelo preditivo baseado em **LSTM (Long Short-Term Memory)** para prever o **preÃ§o de fechamento (D+1)** de uma aÃ§Ã£o da bolsa â€” aqui, **PETR4.SA**.

A soluÃ§Ã£o implementa **toda a pipeline completa**, abrangendo:

- coleta e preparaÃ§Ã£o de dados,
- modelagem e treinamento,
- rastreamento de experimentos,
- deploy do modelo em uma API REST para inferÃªncia,
- monitoramento contÃ­nuo do serviÃ§o.

O projeto demonstra:

- **Modelo LSTM (PyTorch + PyTorch Lightning)** integrado a um pipeline de treinamento estruturado.
- **Rastreabilidade com MLflow:** parÃ¢metros, mÃ©tricas, artefatos.
- **Deploy escalÃ¡vel** via FastAPI com monitoramento por Prometheus.

---

## ğŸŒŸ Arquitetura da SoluÃ§Ã£o (MLOps)

A arquitetura segue o princÃ­pio de **serviÃ§os desacoplados**, separando **treinamento** de **inferÃªncia** para garantir escalabilidade e governanÃ§a.

### Componentes

- **Treinamento â€” `train.py` + PyTorch Lightning**  
  ResponsÃ¡vel por coleta de dados, criaÃ§Ã£o do dataset, construÃ§Ã£o e treinamento do modelo LSTM.

- **InferÃªncia â€” FastAPI (`app/api/main.py`)**  
  API REST que serve o modelo em produÃ§Ã£o com baixa latÃªncia.

- **Rastreabilidade â€” MLflow (SQLite)**  
  Registra cada execuÃ§Ã£o com mÃ©tricas, hiperparÃ¢metros e artefatos.

- **Monitoramento â€” Prometheus**  
  Coleta mÃ©tricas como latÃªncia das requisiÃ§Ãµes e MAE do modelo.

---

## ğŸ› ï¸ Detalhes de ImplementaÃ§Ã£o

### Linguagem e Frameworks

- **Python 3.12.6**
- **PyTorch** â€“ implementaÃ§Ã£o da rede LSTM  
- **PyTorch Lightning** â€“ estrutura e treinamento modularizado  
- **FastAPI** â€“ API REST de inferÃªncia  
- **MLflow** â€“ tracking de experimentos  

### Principais dependÃªncias

- `pandas`, `numpy`, `datetime` â€“ manipulaÃ§Ã£o de dados  
- `yfinance` â€“ coleta de dados financeiros  
- `scikit-learn` â€“ `MinMaxScaler`  
- `torchmetrics` â€“ mÃ©tricas (MAE)  
- `prometheus_client` â€“ monitoramento de serviÃ§o  
- `joblib` â€“ carregamento/salvamento de scaler 
* `uvicorn` (Servidor ASGI). 

### Arquitetura do Modelo

- **LSTM empilhada (duas camadas)** para previsÃ£o de sÃ©ries temporais  
- **`LSTMFactory`** â€“ mÃ³dulo com a arquitetura da rede  
- **`LSTMLightModule`** â€“ mÃ³dulo Lightning que gerencia ciclo de treino, validaÃ§Ã£o e teste  

---

## âœ¨ Principais Conceitos TÃ©cnicos

### ğŸ§  Modelo LSTM

- Arquitetura de duas camadas LSTM com integraÃ§Ã£o ao PyTorch Lightning.
- Reprodutibilidade assegurada com `pl.seed_everything(42)` e `shuffle=False` no DataLoader.

### ğŸ’¾ Deploy (FastAPI)

- Treinamento via CLI e inferÃªncia online desacoplada.
- Carregamento Ãºnico do modelo e scaler no `lifespan`, garantindo baixa latÃªncia.
- `state.py` mantÃ©m instÃ¢ncias globais de `MODEL` e `SCALER` acessÃ­veis a toda a API.

---

## ğŸ“ˆ Monitoramento e EvoluÃ§Ã£o (Sustentabilidade)

### ğŸ” Retreinamento (MLOps)

- **MAE em escala original** Ã© a mÃ©trica crÃ­tica para avaliar a saÃºde do modelo.
- A arquitetura jÃ¡ possui:
  - **mediÃ§Ã£o** (Prometheus)  
  - **aÃ§Ã£o** (`train.py`)  
- Futuro: automatizar o retreinamento acionado por alertas de MAE.

### â±ï¸ Monitoramento de SLA

- **GET `/metrics`** expÃµe mÃ©tricas de latÃªncia e contagem de requisiÃ§Ãµes.
- O SLA pode ser acompanhado via Prometheus/Grafana.
- O modelo estÃ¡ pronto para futura **quantizaÃ§Ã£o** (reduÃ§Ã£o de latÃªncia).

---

## ğŸ—‚ï¸ Estrutura do Projeto

```text
prj-lstm-petr4/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/          
â”‚   â”‚   â”œâ”€â”€ router/
â”‚   â”‚   â”œâ”€â”€ main.py      # FastAPI com Lifespan e Middleware
â”‚   â”‚   â””â”€â”€ state.py     # Estado global (MODEL/SCALER)
â”‚   â”œâ”€â”€ artifacts/        # Checkpoints, scaler.pkl, mlflow.db
â”‚   â”œâ”€â”€ config/           # Settings
â”‚   â”œâ”€â”€ data/             # Pipeline de dados (coleta, Dataset)
â”‚   â”œâ”€â”€ model/            # LSTMFactory e LSTMLightModule
â”‚   â”œâ”€â”€ schemas/          # Entradas/SaÃ­das da API (Pydantic)
â”‚   â””â”€â”€ utils/            # FunÃ§Ãµes auxiliares
â”œâ”€â”€ mlruns/               # Artefatos MLflow
â”œâ”€â”€ requirements.txt
â””â”€â”€ train.py              # Script de Treinamento
```
## ğŸ’» ExecuÃ§Ã£o Local (Windows + Docker + API + Monitoramento)
Esta aplicaÃ§Ã£o faz uso de Prometheus e Grafana para monitoramento em tempo real.
No Windows, Ã© necessÃ¡rio utilizar o Docker Desktop para subir os contÃªineres automaticamente.
VocÃª pode rodar tudo manualmente ou simplesmente utilizar o script **start_ambiente.py**, que:
- Inicia o Docker Desktop
  - Importante jÃ¡ constar instalado, Baixe em: https://www.docker.com/products/docker-desktop/ 
- Sobe (ou cria, se nÃ£o existir) os contÃªineres **prometheus_petr4** e **grafana_petr4**
- Abre automaticamente as URLs no navegador
  - Host Grafana: http://localhost:3000
  - Host Prometheus: http://localhost:9090/targets
- Inicia o servidor FastAPI (Uvicorn)
  - Host API: http://127.0.0.1:8000/docs
### ğŸš€ Passos para ExecuÃ§Ã£o Local

```bash
# 1. Clone o repositÃ³rio
git clone https://github.com/ManoelSa/prj-lstm-petr4.git
cd prj-lstm-petr4

# 2. (Opcional) Crie e ative um ambiente virtual
python -m venv venv
venv\Scripts\activate #Linux: source venv/bin/activate

# 3. Instale as dependÃªncias
pip install -r requirements.txt

# 4. Execute o pipeline de treinamento
python train.py
# SaÃ­da esperada: O modelo serÃ¡ treinado por 50 Ã©pocas e os artefatos serÃ£o salvos em 'artifacts/'

# 6. Inicie o servidor Uvicorn (usando o mÃ³dulo 'api.main')
uvicorn api.main:app --reload
# SaÃ­da esperada: O servidor irÃ¡ iniciar e carregar o modelo PyTorch com sucesso.


```
