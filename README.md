# üìà Previs√£o de S√©ries Temporais Financeiras (PETR4.SA)

## üéØ Objetivo

Este projeto atende ao desafio de desenvolver um modelo preditivo baseado em **LSTM (Long Short-Term Memory)** para prever o **pre√ßo de fechamento (D+1)** de uma a√ß√£o da bolsa ‚Äî aqui, **PETR4.SA**.

A solu√ß√£o implementa **toda a pipeline completa**, abrangendo:

- coleta e prepara√ß√£o de dados,
- modelagem e treinamento,
- rastreamento de experimentos,
- deploy do modelo em uma API REST para infer√™ncia,
- monitoramento cont√≠nuo do servi√ßo.

O projeto demonstra:

- **Modelo LSTM (PyTorch + PyTorch Lightning)** integrado a um pipeline de treinamento estruturado.
- **Rastreabilidade com MLflow:** par√¢metros, m√©tricas, artefatos.
- **Deploy escal√°vel** via FastAPI com monitoramento por Prometheus.

---

## üåü Arquitetura da Solu√ß√£o (MLOps)

A arquitetura segue o princ√≠pio de **servi√ßos desacoplados**, separando **treinamento** de **infer√™ncia** para garantir escalabilidade e governan√ßa.

### Componentes

- **Treinamento ‚Äî `train.py` + PyTorch Lightning**  
  Respons√°vel por coleta de dados, cria√ß√£o do dataset, constru√ß√£o e treinamento do modelo LSTM.

- **Infer√™ncia ‚Äî FastAPI (`app/api/main.py`)**  
  API REST que serve o modelo em produ√ß√£o com baixa lat√™ncia.

- **Rastreabilidade ‚Äî MLflow (SQLite)**  
  Registra cada execu√ß√£o com m√©tricas, hiperpar√¢metros e artefatos.

- **Monitoramento ‚Äî Prometheus**  
  Coleta m√©tricas como lat√™ncia das requisi√ß√µes e MAE do modelo.

---

## üõ†Ô∏è Detalhes de Implementa√ß√£o

### Linguagem e Frameworks

- **Python 3.12.6**
- **PyTorch** ‚Äì implementa√ß√£o da rede LSTM  
- **PyTorch Lightning** ‚Äì estrutura e treinamento modularizado  
- **FastAPI** ‚Äì API REST de infer√™ncia  
- **MLflow** ‚Äì tracking de experimentos  

### Principais depend√™ncias

- `pandas`, `numpy`, `datetime` ‚Äì manipula√ß√£o de dados  
- `yfinance` ‚Äì coleta de dados financeiros  
- `scikit-learn` ‚Äì `MinMaxScaler`  
- `torchmetrics` ‚Äì m√©tricas (MAE)  
- `prometheus_client` ‚Äì monitoramento de servi√ßo  
- `joblib` ‚Äì carregamento/salvamento de scaler 
* `uvicorn` (Servidor ASGI). 

### Arquitetura do Modelo

- **LSTM empilhada (duas camadas)** para previs√£o de s√©ries temporais  
- **`LSTMFactory`** ‚Äì m√≥dulo com a arquitetura da rede  
- **`LSTMLightModule`** ‚Äì m√≥dulo Lightning que gerencia ciclo de treino, valida√ß√£o e teste  

---

## ‚ú® Principais Conceitos T√©cnicos

### üß† Modelo LSTM

- Arquitetura de duas camadas LSTM com integra√ß√£o ao PyTorch Lightning.
- Reprodutibilidade assegurada com `pl.seed_everything(42)` e `shuffle=False` no DataLoader.

### üíæ Deploy (FastAPI)

- Treinamento via CLI e infer√™ncia online desacoplada.
- Carregamento √∫nico do modelo e scaler no `lifespan`, garantindo baixa lat√™ncia.
- `state.py` mant√©m inst√¢ncias globais de `MODEL` e `SCALER` acess√≠veis a toda a API.

---

## üìà Monitoramento e Evolu√ß√£o (Sustentabilidade)

### üîÅ Retreinamento (MLOps)

- **MAE em escala original** √© a m√©trica cr√≠tica para avaliar a sa√∫de do modelo.
- A arquitetura j√° possui:
  - **medi√ß√£o** (Prometheus)  
  - **a√ß√£o** (`train.py`)  
- Futuro: automatizar o retreinamento acionado por alertas de MAE.

### ‚è±Ô∏è Monitoramento de SLA

- **GET `/metrics`** exp√µe m√©tricas de lat√™ncia e contagem de requisi√ß√µes.
- O SLA pode ser acompanhado via Prometheus/Grafana.

---

## üóÇÔ∏è Estrutura do Projeto

```text
prj-lstm-petr4/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ api/          
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ router/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py      # FastAPI com Lifespan e Middleware
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ state.py     # Estado global (MODEL/SCALER)
‚îÇ   ‚îú‚îÄ‚îÄ artifacts/        # Checkpoints, scaler.pkl, mlflow.db
‚îÇ   ‚îú‚îÄ‚îÄ config/           # Settings
‚îÇ   ‚îú‚îÄ‚îÄ data/             # Pipeline de dados (coleta, Dataset)
‚îÇ   ‚îú‚îÄ‚îÄ model/            # LSTMFactory e LSTMLightModule
‚îÇ   ‚îú‚îÄ‚îÄ schemas/          # Entradas/Sa√≠das da API (Pydantic)
‚îÇ   ‚îî‚îÄ‚îÄ utils/            # Fun√ß√µes auxiliares
‚îú‚îÄ‚îÄ mlruns/               # Artefatos MLflow
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ train.py              # Script de Treinamento
```
## üíª Execu√ß√£o Local (Windows + Docker + API + Monitoramento)
Esta aplica√ß√£o faz uso de Prometheus e Grafana para monitoramento em tempo real.
No Windows, √© necess√°rio utilizar o Docker Desktop para subir os cont√™ineres automaticamente.
Voc√™ pode rodar tudo manualmente ou simplesmente utilizar o script **start_ambiente.py**, que:
- Inicia o Docker Desktop
  - Importante j√° constar instalado, Baixe em: https://www.docker.com/products/docker-desktop/ 
- Sobe (ou cria, se n√£o existir) os cont√™ineres **prometheus_petr4** e **grafana_petr4**
- Abre automaticamente as URLs no navegador
  - Host Grafana: http://localhost:3000
  - Host Prometheus: http://localhost:9090/targets
- Inicia o servidor FastAPI (Uvicorn)
  - Host API: http://127.0.0.1:8000/docs

Obs.: Para executar o script **start_ambiente.py** √© importante seguir primeiro os passos abaixo.

### üöÄ Passos para Execu√ß√£o Local

```bash
# 1. Clone o reposit√≥rio
git clone https://github.com/ManoelSa/prj-lstm-petr4.git
cd prj-lstm-petr4

# 2. (Opcional) Crie e ative um ambiente virtual
python -m venv venv
venv\Scripts\activate #Linux: source venv/bin/activate

# 3. Instale as depend√™ncias
pip install -r requirements.txt

# 4. Execute o pipeline de treinamento
python train.py
# Sa√≠da esperada: O modelo ser√° treinado por 50 √©pocas e os artefatos ser√£o salvos em 'artifacts/'
```
## üîé An√°lise de Experimentos com MLflow

Ap√≥s iniciar os steps atenteriores, √© hora de explorar, come√ßando com interface do MLflow:
-  Execute: `mlflow ui --backend-store-uri sqlite:///app/artifacts/mlflow.db`
- Host: `http://127.0.0.1:5000/`

Utilize os seguintes pontos para analisar a performance e a rastreabilidade do modelo:

### 1. Rastreamento e Reprodutibilidade (Par√¢metros)

Ao clicar no ID de uma **Run (Execu√ß√£o)**, o primeiro foco √© na se√ß√£o **Par√¢metros**.

* **Verifica√ß√£o de Hiperpar√¢metros:** Confirme que os par√¢metros do modelo (`hidden_size`, `dropout_rate`, `learning_rate`) e do treino (`epochs`, `batch_size`) foram logados automaticamente pelo PyTorch Lightning.
* **Verifica√ß√£o de Par√¢metros de Dados:** Procure os logs manuais (`data_ticker`, `data_time_step`, `data_start_date`). **Estes comprovam a rastreabilidade:** possibilitando saber exatamente com quais configura√ß√µes e dados o modelo foi treinado.

### 2. An√°lise de Desempenho (M√©tricas)

Utilize a se√ß√£o **M√©tricas** para avaliar a qualidade do modelo ao longo do tempo.

* **Curva de `val_loss` (Perda de Valida√ß√£o):** Este √© o gr√°fico mais importante. A curva deve cair de forma consistente e depois se estabilizar. Se a curva come√ßar a subir, indica **overfitting** (o modelo est√° memorizando o treino e perdendo a capacidade de generaliza√ß√£o).
* **M√©trica de Produ√ß√£o (`test_mae`):** Verifique o valor final do `test_mae` (Mean Absolute Error). Este valor, que √© uma **m√©trica escalonada**, deve ser baixo. Ele se correlaciona diretamente com o **MAE em R$** calculado na etapa final do `train.py`.

A interface do **MLflow** atua como o Registro de Experimentos (Model Registry), fornecendo um hist√≥rico completo para auditoria e garantindo que o modelo seja rastre√°vel e audit√°vel.


## üìä Monitoramento em Grafana (An√°lise de Produ√ß√£o)

Para analisar a sa√∫de do servi√ßo (SLA) e a efetividade do modelo, utilizamos o Prometheus e o Grafana, habilitados nos passos anteriores.

Apesar da automa√ß√£o, ainda √© necess√°rio realizar duas configura√ß√µes manuais no Grafana:

1.  **Conex√£o do Data Source (Prometheus):**
    * Acesse o Grafana (`http://localhost:3000`).
    * V√° para **Data Sources** e adicione o Prometheus.
    * No campo **URL**, utilize o endere√ßo do servi√ßo: `http://host.docker.internal:9090` (Este √© o endere√ßo que permite ao Grafana acessar o Prometheus que est√° rodando no cont√™iner).
    * Clique em "Save & Test".

2.  **Importa√ß√£o do Dashboard:**
    * V√° para `Dashboards` -> `New` -> `Import`.
    * Selecione o JSON do seu dashboard (localizado na pasta `metrics/`).
    * Na importa√ß√£o, estabele√ßa um nome e uma pasta para seu dashboard, e fim, pronto para uso.